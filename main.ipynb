{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "from scipy.stats import linregress\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeff's code starts here\n",
    "filenames = glob('Resources/StormEvent*.csv')\n",
    "Storm_Event_df = [pd.read_csv(f, dtype = str) for f in filenames]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>35.17</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104928</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.60</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104929</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BEGIN_YEARMONTH BEGIN_DAY BEGIN_TIME END_YEARMONTH END_DAY END_TIME  \\\n",
       "0          195004        28       1445        195004      28     1445   \n",
       "1          195004        29       1530        195004      29     1530   \n",
       "2          195007         5       1800        195007       5     1800   \n",
       "3          195007         5       1830        195007       5     1830   \n",
       "4          195007        24       1440        195007      24     1440   \n",
       "\n",
       "  EPISODE_ID  EVENT_ID         STATE STATE_FIPS  ... END_RANGE END_AZIMUTH  \\\n",
       "0        NaN  10096222      OKLAHOMA         40  ...         0         NaN   \n",
       "1        NaN  10120412         TEXAS         48  ...         0         NaN   \n",
       "2        NaN  10104927  PENNSYLVANIA         42  ...         0         NaN   \n",
       "3        NaN  10104928  PENNSYLVANIA         42  ...         0         NaN   \n",
       "4        NaN  10104929  PENNSYLVANIA         42  ...         0         NaN   \n",
       "\n",
       "  END_LOCATION BEGIN_LAT BEGIN_LON END_LAT END_LON EPISODE_NARRATIVE  \\\n",
       "0          NaN     35.12    -99.20   35.17  -99.20               NaN   \n",
       "1          NaN     31.90    -98.60   31.73  -98.60               NaN   \n",
       "2          NaN     40.58    -75.70   40.65  -75.47               NaN   \n",
       "3          NaN     40.60    -76.75     NaN     NaN               NaN   \n",
       "4          NaN     41.63    -79.68     NaN     NaN               NaN   \n",
       "\n",
       "  EVENT_NARRATIVE DATA_SOURCE  \n",
       "0             NaN         PUB  \n",
       "1             NaN         PUB  \n",
       "2             NaN         PUB  \n",
       "3             NaN         PUB  \n",
       "4             NaN         PUB  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Storm_Event_Combined_df=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(Storm_Event_df)):\n",
    "    Storm_Event_Combined_df = Storm_Event_Combined_df.append(Storm_Event_df[i])\n",
    "#Storm_Event_df\n",
    "\n",
    "Storm_Event_Combined_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jeff's code ends here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CDSD</th>\n",
       "      <th>DSND</th>\n",
       "      <th>DSNW</th>\n",
       "      <th>EMNT</th>\n",
       "      <th>EMSD</th>\n",
       "      <th>EMSN</th>\n",
       "      <th>EMXP</th>\n",
       "      <th>...</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>WDMV</th>\n",
       "      <th>AWND</th>\n",
       "      <th>TSUN</th>\n",
       "      <th>WDF2</th>\n",
       "      <th>WDF5</th>\n",
       "      <th>WSF2</th>\n",
       "      <th>WSF5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>...</td>\n",
       "      <td>51.8</td>\n",
       "      <td>61.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION        NAME     DATE CDSD DSND DSNW EMNT EMSD EMSN  EMXP  ...  \\\n",
       "0  USC00210018  ADA, MN US  1950-01  NaN  NaN  NaN  -33  NaN  NaN  0.50  ...   \n",
       "1  USC00210018  ADA, MN US  1950-02  NaN  NaN    1  -32  NaN  1.0  0.10  ...   \n",
       "2  USC00210018  ADA, MN US  1950-03  NaN  NaN    0  -25  NaN  0.3  0.91  ...   \n",
       "3  USC00210018  ADA, MN US  1950-04  NaN  NaN  NaN    5  NaN  NaN   NaN  ...   \n",
       "4  USC00210018  ADA, MN US  1950-05  NaN    0    0   30    0  0.0  1.40  ...   \n",
       "\n",
       "   TAVG  TMAX   TMIN WDMV AWND TSUN WDF2 WDF5 WSF2 WSF5  \n",
       "0   NaN   NaN  -16.4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1   7.1  19.1   -5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  19.5  29.5    9.4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  32.8  41.0   24.7  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  51.8  61.6   42.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faduma's code starts here\n",
    "filenames = glob('Temperature_Data/Temperature_Data*.csv')\n",
    "Temp_Data_df = [pd.read_csv(f, dtype = str) for f in filenames]\n",
    "\n",
    "Temp_Data_Combined_df=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(Temp_Data_df)):\n",
    "    Temp_Data_Combined_df = Temp_Data_Combined_df.append(Temp_Data_df[i])\n",
    "    \n",
    "#combined file name:\n",
    "Temp_Data_Combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faduma's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kristina's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CDSD</th>\n",
       "      <th>DSND</th>\n",
       "      <th>DSNW</th>\n",
       "      <th>EMNT</th>\n",
       "      <th>EMSD</th>\n",
       "      <th>EMSN</th>\n",
       "      <th>EMXP</th>\n",
       "      <th>...</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>WDMV</th>\n",
       "      <th>AWND</th>\n",
       "      <th>TSUN</th>\n",
       "      <th>WDF2</th>\n",
       "      <th>WDF5</th>\n",
       "      <th>WSF2</th>\n",
       "      <th>WSF5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1950-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>...</td>\n",
       "      <td>51.8</td>\n",
       "      <td>61.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1962-03</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>-26</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>23.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1962-04</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>28.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1962-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>...</td>\n",
       "      <td>55.4</td>\n",
       "      <td>66.4</td>\n",
       "      <td>44.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1962-06</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>USC00210018</td>\n",
       "      <td>ADA, MN US</td>\n",
       "      <td>1962-07</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>56.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATION        NAME     DATE CDSD DSND DSNW EMNT EMSD EMSN  EMXP  \\\n",
       "0    USC00210018  ADA, MN US  1950-01  NaN  NaN  NaN  -33  NaN  NaN  0.50   \n",
       "1    USC00210018  ADA, MN US  1950-02  NaN  NaN    1  -32  NaN  1.0  0.10   \n",
       "2    USC00210018  ADA, MN US  1950-03  NaN  NaN    0  -25  NaN  0.3  0.91   \n",
       "3    USC00210018  ADA, MN US  1950-04  NaN  NaN  NaN    5  NaN  NaN   NaN   \n",
       "4    USC00210018  ADA, MN US  1950-05  NaN    0    0   30    0  0.0  1.40   \n",
       "..           ...         ...      ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "145  USC00210018  ADA, MN US  1962-03    0   31    5  -26   17  3.0  0.30   \n",
       "146  USC00210018  ADA, MN US  1962-04    2  NaN    0   15  NaN  0.0  0.69   \n",
       "147  USC00210018  ADA, MN US  1962-05    2    0    0   27    0  0.0  1.75   \n",
       "148  USC00210018  ADA, MN US  1962-06  101    0    0   40    0  0.0  1.70   \n",
       "149  USC00210018  ADA, MN US  1962-07  208    0    0   46    0  0.0  2.77   \n",
       "\n",
       "     ...  TAVG  TMAX   TMIN WDMV AWND TSUN WDF2 WDF5 WSF2 WSF5  \n",
       "0    ...   NaN   NaN  -16.4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1    ...   7.1  19.1   -5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2    ...  19.5  29.5    9.4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3    ...  32.8  41.0   24.7  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4    ...  51.8  61.6   42.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "..   ...   ...   ...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "145  ...  23.7  31.6   15.8  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "146  ...  40.0  51.7   28.2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "147  ...  55.4  66.4   44.5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "148  ...  66.0  76.7   55.3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "149  ...  68.3  80.3   56.3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[150 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View existing dataframe\n",
    "Temp_Data_Combined_df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STATION',\n",
       " 'NAME',\n",
       " 'DATE',\n",
       " 'CDSD',\n",
       " 'DSND',\n",
       " 'DSNW',\n",
       " 'EMNT',\n",
       " 'EMSD',\n",
       " 'EMSN',\n",
       " 'EMXP',\n",
       " 'EMXT',\n",
       " 'HDSD',\n",
       " 'PRCP',\n",
       " 'SNOW',\n",
       " 'TAVG',\n",
       " 'TMAX',\n",
       " 'TMIN',\n",
       " 'WDMV',\n",
       " 'AWND',\n",
       " 'TSUN',\n",
       " 'WDF2',\n",
       " 'WDF5',\n",
       " 'WSF2',\n",
       " 'WSF5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Temp_Data_Combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                NAME     DATE  PRCP  SNOW  TAVG  TMAX   TMIN\n",
      "0                         ADA, MN US  1950-01  1.30   NaN   NaN   NaN  -16.4\n",
      "1                         ADA, MN US  1950-02  0.10   1.0   7.1  19.1   -5.0\n",
      "2                         ADA, MN US  1950-03  1.14   0.3  19.5  29.5    9.4\n",
      "3                         ADA, MN US  1950-04   NaN   NaN  32.8  41.0   24.7\n",
      "4                         ADA, MN US  1950-05  5.21   0.0  51.8  61.6   42.0\n",
      "...                              ...      ...   ...   ...   ...   ...    ...\n",
      "2502  COLLEGEVILLE ST. JOHN S, MN US  2019-09  8.67     0  62.6  71.6   53.6\n",
      "2503  COLLEGEVILLE ST. JOHN S, MN US  2019-10  4.17     0  44.6  53.1   36.2\n",
      "2504  COLLEGEVILLE ST. JOHN S, MN US  2019-11   1.6  14.1  28.1  34.1   22.1\n",
      "2505  COLLEGEVILLE ST. JOHN S, MN US  2019-12  2.12    12  18.6  26.1   11.2\n",
      "2506  COLLEGEVILLE ST. JOHN S, MN US  2020-01  0.93  14.4  16.2  24.1    8.3\n",
      "\n",
      "[7030 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# keeping only the columns that are relevant\n",
    "clean_temp_data_df = Temp_Data_Combined_df[['NAME','DATE','PRCP','SNOW','TAVG','TMAX','TMIN']]\n",
    "print(clean_temp_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADA, MN US', 'CLOQUET, MN US', 'ROSEAU, MN US',\n",
       "       'WINNIBIGOSHISH DAM, MN US', 'WARROAD, MN US', 'HALLOCK, MN US',\n",
       "       'ALEXANDRIA CHANDLER FIELD, MN US', 'CANBY, MN US',\n",
       "       'COLLEGEVILLE ST. JOHN S, MN US'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column headers\n",
    "clean_temp_data_df = clean_temp_data_df.rename(columns={\n",
    "    \"NAME\": \"Name\",\n",
    "    \"DATE\": \"Date\",\n",
    "    \"PRCP\": \"Total Monthly Precipitation\",\n",
    "    \"SNOW\": \"Total Montly Snowfall (mm)\",\n",
    "    \"TAVG\": \"Avg Monthly Temp\", \n",
    "    \"TMAX\": \"Monthly Mean Max Temp\",\n",
    "    \"TMIN\": \"Monthly Mean Min Temp\"\n",
    "})\n",
    "clean_temp_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temp_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Nan values and drop them.\n",
    "cleaner_temp_data_df = clean_temp_data_df.dropna(how='any', inplace=False)\n",
    "cleaner_temp_data_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_temp_data_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaner_temp_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to csv\n",
    "clean_temp_data_df.to_csv('Resources/clean_temp_data.csv', index=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kristina's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily's code starts here\n",
    "# View existing dataframe\n",
    "Storm_Event_Combined_df.head(150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(Storm_Event_Combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the columns that are relevant\n",
    "clean_storm_data_df = Storm_Event_Combined_df[['YEAR','MONTH_NAME','BEGIN_DAY','STATE','EVENT_TYPE']]\n",
    "\n",
    "# filtering the data based on weather in Minnesota\n",
    "clean_storm_data_mn_df = clean_storm_data_df[clean_storm_data_df['STATE'] == 'MINNESOTA']\n",
    "clean_storm_data_mn_df.head()\n",
    "\n",
    "# rename the columns\n",
    "clean_storm_data_mn_df = clean_storm_data_mn_df.rename(columns={\n",
    "    \"YEAR\": \"Year\",\n",
    "    \"MONTH_NAME\": \"Month\",\n",
    "    \"BEGIN_DAY\": \"Day\",\n",
    "    \"STATE\": \"State\",\n",
    "    \"EVENT_TYPE\": \"Event Type\",\n",
    "})\n",
    "\n",
    "# check number of rows and columns\n",
    "clean_storm_data_mn_df.shape\n",
    "\n",
    "# view all unique event types\n",
    "clean_storm_data_mn_df['Event Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the data\n",
    "len(clean_storm_data_mn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to check for Nan values and drop them\n",
    "clean_storm_df = clean_storm_data_mn_df.dropna(how='any', inplace=False)\n",
    "clean_storm_df.head()\n",
    "len(clean_storm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_storm_df['Event Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update 'THUNDERSTORM WINDS/HEAVY RAIN' to proper case\n",
    "clean_storm_df['Event Type'] = clean_storm_df['Event Type'].replace({\n",
    "    'THUNDERSTORM WINDS/HEAVY RAIN':'Thunderstorm Winds/Heavy Rain',\n",
    "    'Blizzard': 'Winter Weather', \n",
    "    'Heavy Snow': 'Winter Weather',\n",
    "    'Ice Storm': 'Winter Weather',\n",
    "    'Lake-Effect Snow': 'Winter Weather',\n",
    "    'Sleet': 'Winter Weather', \n",
    "    'Winter Storm': 'Winter Weather'\n",
    "})\n",
    "clean_storm_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review value counts of Event Type\n",
    "clean_storm_df['Event Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to csv\n",
    "clean_storm_df.to_csv('Resources/clean_storm_event_data.csv', index=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of cleaned storm data - should be moved to analysis routine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing by Jeff\n",
    "year_list = clean_storm_data_mn_df[\"Year\"].unique()\n",
    "event_list = clean_storm_data_mn_df[\"Event Type\"].unique()\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_storm_data_mn_df[clean_storm_data_mn_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Storm Events vs Year\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing by Jeff\n",
    "#Isolating just the Tornado data (data set from 1950-2020)\n",
    "\n",
    "year_list = clean_storm_data_mn_df[\"Year\"].unique()\n",
    "event_list = clean_storm_data_mn_df[\"Event Type\"].unique()\n",
    "clean_tornado_mn_df = pd.DataFrame()\n",
    "clean_tornado_mn_df = clean_storm_data_mn_df[clean_storm_data_mn_df[\"Event Type\"]==\"Tornado\"]\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_tornado_mn_df[clean_tornado_mn_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Tornado Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing by Jeff\n",
    "year_list = clean_storm_data_mn_df[\"Year\"].unique()\n",
    "event_list = clean_storm_data_mn_df[\"Event Type\"].unique()\n",
    "clean_tornado_mn_df = pd.DataFrame()\n",
    "clean_tornado_mn_df = clean_storm_data_mn_df[clean_storm_data_mn_df[\"Year\"]>\"1995\"]\n",
    "\n",
    "#clean_storm_data_mn_df looking beyond 1995 only\n",
    "count_g1995_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    if i > \"1995\":\n",
    "        count_g1995 = clean_tornado_mn_df[clean_tornado_mn_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "        count_g1995_df = count_g1995_df.append({\"Year\":i, \"Count\":count_g1995}, ignore_index=True)\n",
    "\n",
    "\n",
    "x_data = (count_g1995_df[\"Year\"].astype(int))\n",
    "y_data = count_g1995_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of All Events vs Year past 1995\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more code by Jeff\n",
    "event_count_df = pd.DataFrame()\n",
    "for i in event_list:\n",
    "    event_count = clean_storm_data_mn_df[clean_storm_data_mn_df[\"Event Type\"]==i][\"Event Type\"].count()\n",
    "    event_count_df = event_count_df.append({\"Event Type\":i, \"Count\":event_count}, ignore_index=True)\n",
    "event_count_df = event_count_df.sort_values(by = \"Count\", ascending = False)\n",
    "\n",
    "\n",
    "total = event_count_df[\"Count\"].sum()\n",
    "event_count_df[\"Percent\"] = event_count_df[\"Count\"]/total*100\n",
    "event_count_ge1_df = pd.DataFrame()\n",
    "event_count_ge1_df = event_count_df[event_count_df[\"Percent\"]>=1]\n",
    "\n",
    "x_data = event_count_ge1_df[\"Event Type\"].astype(object)\n",
    "y_data = event_count_ge1_df[\"Count\"].astype(float)\n",
    "x_list = x_data.tolist()\n",
    "y_list = y_data.tolist()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.xticks(rotation=90)\n",
    "ax.bar(x_list,y_list)\n",
    "plt.show()\n",
    "\n",
    "event_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily's code ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
