{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import random as random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import f_oneway\n",
    "import requests\n",
    "import json \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeff Code\n",
    "\n",
    "#Functions to be used for code\n",
    "\n",
    "#Function #1\n",
    "#plotting routine with regression (setting up as a function)\n",
    "#below function takes 2 sets of x and y data and generates a scatter plot for each.  Then performs a linear regression \n",
    "#and returns a dataframe with the regression results\n",
    "#x and y are number pairs\n",
    "#data is the name of what is being plotted (like temperature).  used as Y axis label and as part of title\n",
    "#prints results of regression below graphs\n",
    "\n",
    "def plotter(x1,y1,Data1,x2,y2,Data2):\n",
    "   \n",
    "   #plotting data set x1 and y1\n",
    "\n",
    "    (slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x1,y1)\n",
    "    regress_values_N = x1 * slope_N + intercept_N\n",
    "    line_eq = \"y = \" + str(round(slope_N,3)) + \"x + \" + str(round(intercept_N,3))+\", r = \" +str(round(rvalue_N,3))\\\n",
    "                        + \" p = \"+str(round(pvalue_N,3))\n",
    "    max_y = y1.max()\n",
    "    min_x = x1.min()\n",
    "    fig = plt.figure(figsize = (15,4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.scatter(x1, y1, s=5)\n",
    "    plt.plot(x1,regress_values_N,\"r-\")\n",
    "    plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(f\"{Data1} \")\n",
    "    plt.title(f\"{Data1} vs Year\")\n",
    "\n",
    "  #plotting data set x2 and y2\n",
    "    (slope_S, intercept_S, rvalue_S, pvalue_S, stderr_S) = linregress(x2,y2)\n",
    "    regress_values_S = x2 * slope_S + intercept_S\n",
    "    line_eq = \"y = \" + str(round(slope_S,3)) + \"x + \" + str(round(intercept_S,3))+\", r = \" +str(round(rvalue_S,3))\\\n",
    "                        + \" p = \"+str(round(pvalue_S,3))\n",
    "    max_y = y2.max()\n",
    "    min_x = x2.min()\n",
    "    #plotting second data set\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(x2, y2, s=5)\n",
    "    plt.plot(x2,regress_values_S,\"r-\")\n",
    "    plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(f\"{Data2}\")\n",
    "    plt.title(f\"{Data2} vs Year\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    Result_Temp_df = pd.DataFrame({\"Slope\":[slope_N, slope_S], \"Intercept\":[intercept_N, intercept_S], \n",
    "                                                         \"r-value\":[rvalue_N, rvalue_S], \"p-value\":[pvalue_N, pvalue_S]})\n",
    "\n",
    "    Result_Temp_df[\"Param\"] =[Data1, Data2]\n",
    "    Result_Temp_df = Result_Temp_df[[\"Param\", \"Slope\", \"Intercept\", \"r-value\", \"p-value\"]]\n",
    "\n",
    "    print(f\"Correlation Results\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(Result_Temp_df)\n",
    "    return Result_Temp_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kristina's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kristina's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeff's code starts here\n",
    "\n",
    "#reading in raw data\n",
    "temp_data_df = pd.read_csv('Resources/clean_temp_data.csv')\n",
    "#temp_data_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to understand impact of removing data on column length\n",
    "print(\"Results of Cleaning up Data (removing NaN)\")\n",
    "print(\"\")\n",
    "names = temp_data_df.columns\n",
    "print(\"Before\")\n",
    "for i in names:\n",
    "    full = temp_data_df[i].count()\n",
    "    Null = temp_data_df[i].isnull().sum(axis = 0)\n",
    "    print(f\"for {i} column: Full {full} vs Empty or NaN {Null}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final clean up of Data\n",
    "\n",
    "#removing NaN\n",
    "Start_Length = len(temp_data_df[\"Date\"])\n",
    "temp_data_df.dropna(inplace = True)\n",
    "\n",
    "#temp_data_df\n",
    "Finish_Length = len(temp_data_df[\"Date\"])\n",
    "print(f\"Temperature and precipitation data starts with {Start_Length} records\")\n",
    "print(f\"After removing rows with empty data fields have {Finish_Length} records\")\n",
    "\n",
    "#Creating Seasonal Averages\n",
    "    #Winter - Dec, Jan, Feb\n",
    "    #Spring - March, April, May\n",
    "    #Summer - June, July, August\n",
    "    #Fall - Sept, Oct, Nov\n",
    "\n",
    "#code below combines all locations into one average value for month and year\n",
    "list = temp_data_df[\"Name\"].unique()\n",
    "temp_comb_df = temp_data_df.groupby([\"Date\"])[\"Total Monthly Precipitation\", \"Total Montly Snowfall (mm)\",\n",
    "                                             \"Avg Monthly Temp\", \"Monthly Mean Max Temp\",\n",
    "                                              \"Monthly Mean Min Temp\"].mean().reset_index()\n",
    "\n",
    "#Data is string Year-Month (month two digits 01-12).  This splits into two fields\n",
    "temp_comb_df[\"Month\"] = temp_comb_df[\"Date\"].str.split(\"-\").str[1].astype(int)\n",
    "temp_comb_df[\"Year\"] = temp_comb_df[\"Date\"].str.split(\"-\").str[0].astype(int)\n",
    "\n",
    "col_list = temp_comb_df.columns.tolist()\n",
    "Season_data_df = pd.DataFrame(columns = col_list)\n",
    "\n",
    "#combining months to form seasons: Winter (Dec-Feb), Fall(Mar-May), Summer(June-Aug), Fall(Sept-Nov)\n",
    "for i in temp_comb_df[\"Year\"].unique():\n",
    "    if i!= 1950 and i!= 2020: #ignore 1950 because don't have dec 1949 and don't have all 2020\n",
    "        \n",
    "        #in dataframe the \"month\" represents the season: 2=winter, 4 = spring, 7 = summer, 10=fall\n",
    "        #winter data is complicated because Dec is previous year\n",
    "        winter_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(1,2)))|\\\n",
    "                                         ((temp_comb_df[\"Year\"]==(i-1)) & (temp_comb_df[\"Month\"]==12))].mean()\n",
    "        winter_data[\"Year\"]=winter_data[\"Year\"].astype(int)+1 # extra 1 because rounds down to year previous\n",
    "        winter_data[\"Month\"] = 1 #would be 5 otherwise (mean(12,1,2))\n",
    "        \n",
    "        #isolating spring data\n",
    "        spring_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(3,5)))].mean()\n",
    "        spring_data[\"Year\"]=spring_data[\"Year\"].astype(int)\n",
    "        \n",
    "        #Isolating summer data\n",
    "        summer_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(6,8)))].mean()\n",
    "        summer_data[\"Year\"]=summer_data[\"Year\"].astype(int)\n",
    "        \n",
    "        #isolating fall\n",
    "        fall_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(9,11)))].mean() \n",
    "        fall_data[\"Year\"]=fall_data[\"Year\"].astype(int)\n",
    "        \n",
    "        #combining together all seasons into one data frame\n",
    "        frames = [winter_data, spring_data, summer_data, fall_data]\n",
    "        Season_data_df = Season_data_df.append(frames, ignore_index = True)\n",
    "        \n",
    "winter = 1\n",
    "sprint = 4\n",
    "summer = 7\n",
    "fall = 10\n",
    "Season_data_df[\"Temp Swing\"] = Season_data_df[\"Monthly Mean Max Temp\"]-Season_data_df[\"Monthly Mean Min Temp\"]\n",
    "Season_data_df.drop(columns=[\"Date\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = \"Avg Monthly Temp\"\n",
    "x1 =  Season_data_df[Season_data_df[\"Month\"]==summer][\"Year\"]\n",
    "y1 =  Season_data_df[Season_data_df[\"Month\"]==summer][Data1]\n",
    "Data2 = \"Avg Monthly Temp\"\n",
    "x2 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y2 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data2]\n",
    "print(\"\")\n",
    "print(f\"Avg Temperatures (F) for Winter and Summer Months\")\n",
    "print(\"\")\n",
    "Data1 = Data1 + \" (Summer)\"\n",
    "Data2= Data2 + \" (Winter)\"\n",
    "Correlation_df = plotter(x1,y1,Data1,x2,y2,Data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = \"Monthly Mean Min Temp\"\n",
    "x1 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y1 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data1]\n",
    "Data2 = \"Monthly Mean Max Temp\"\n",
    "x2 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y2 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data2]\n",
    "print(\"\")\n",
    "print(f\"Minimum and Maximum Avg Temperatures for Winter Months\")\n",
    "print(\"\")\n",
    "Data1 = Data1 + \" (Winter)\"\n",
    "Data2= Data2 + \" (Winter)\"\n",
    "Correlation_df = plotter(x1,y1,Data1,x2,y2,Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = \"Temp Swing\"\n",
    "x1 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y1 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data1]\n",
    "Data2 = \"Temp Swing\"\n",
    "x2 =  Season_data_df[Season_data_df[\"Month\"]==summer][\"Year\"]\n",
    "y2 =  Season_data_df[Season_data_df[\"Month\"]==summer][Data2]\n",
    "print(\"\")\n",
    "print(f\"Avg Temperature Swings for Winter and Summer (Seasonal max - seasonal min)\")\n",
    "print(\"\")\n",
    "Data1 = Data1 +\" Winter\"\n",
    "Data2 = Data2 +\" Summer\"\n",
    "Correlation_df = plotter(x1,y1,Data1,x2,y2,Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Winter\n",
    "#ANOVA\n",
    "#binning data for analysis\n",
    "year_min = Season_data_df[\"Year\"].min()\n",
    "year_max = Season_data_df[\"Year\"].max()\n",
    "delta_year = year_max-year_min\n",
    "delta_year\n",
    "bin_size = 17 #number of years\n",
    "\n",
    "bins = [(year_min+i*bin_size) for i in range(0,int(delta_year/bin_size)+1)]\n",
    "groups = [((i-1)*bin_size+(1951+bin_size/2)) for i in range(1,int(delta_year/bin_size)+1)]\n",
    "Season_data_df[\"Bin\"]=pd.cut(Season_data_df[\"Year\"],bins, labels = groups, include_lowest = True)\n",
    "\n",
    "#plotting average for bins\n",
    "x_label = groups\n",
    "y_label = [Season_data_df[(Season_data_df[\"Bin\"]==i)&(Season_data_df[\"Month\"]==winter)][\"Temp Swing\"].mean() for i in groups]\n",
    "plt.scatter(x_label,y_label,s = 20)\n",
    "plt.title(f\"Temp Swing (Max-Min) for Winter (bin size {bin_size} years)\")\n",
    "plt.xlabel(f\"Year bin - size {bin_size} years\")\n",
    "plt.ylabel('Temp Swing (Max-Min)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#box plot of full data in bins\n",
    "red_diamond = dict(markerfacecolor='r', marker='D')\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Temperature Swing in Winter')\n",
    "ax1.set_ylabel('Temp Swing (Ma)')\n",
    "ax1.set_xlabel(f\"Year bin - size {bin_size} years\")\n",
    "\n",
    "ax1.boxplot([Season_data_df[(Season_data_df[\"Bin\"]==i)&(Season_data_df[\"Month\"]==winter)][\"Temp Swing\"] for i in groups], labels=groups,showfliers = True,\n",
    "            flierprops = red_diamond)\n",
    "plt.show()\n",
    "\n",
    "bin_1 = Season_data_df[Season_data_df[\"Bin\"]==groups[0]][\"Temp Swing\"].tolist()\n",
    "bin_2 = Season_data_df[Season_data_df[\"Bin\"]==groups[1]][\"Temp Swing\"].tolist()\n",
    "bin_3 = Season_data_df[Season_data_df[\"Bin\"]==groups[2]][\"Temp Swing\"].tolist()\n",
    "bin_4 = Season_data_df[Season_data_df[\"Bin\"]==groups[3]][\"Temp Swing\"].tolist()\n",
    "f_oneway(bin_1, bin_2, bin_3, bin_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Summer\n",
    "#ANOVA\n",
    "#binning data for analysis\n",
    "year_min = Season_data_df[\"Year\"].min()\n",
    "year_max = Season_data_df[\"Year\"].max()\n",
    "delta_year = year_max-year_min\n",
    "delta_year\n",
    "bin_size = 17 #number of years\n",
    "\n",
    "bins = [(year_min+i*bin_size) for i in range(0,int(delta_year/bin_size)+1)]\n",
    "groups = [((i-1)*bin_size+(1951+bin_size/2)) for i in range(1,int(delta_year/bin_size)+1)]\n",
    "Season_data_df[\"Bin\"]=pd.cut(Season_data_df[\"Year\"],bins, labels = groups, include_lowest = True)\n",
    "\n",
    "#plotting average for bins\n",
    "x_label = groups\n",
    "y_label = [Season_data_df[(Season_data_df[\"Bin\"]==i)&(Season_data_df[\"Month\"]==summer)][\"Temp Swing\"].mean() for i in groups]\n",
    "plt.scatter(x_label,y_label,s = 20)\n",
    "plt.title(f\"Temp Swing (Max-Min) for Winter (bin size {bin_size} years)\")\n",
    "plt.xlabel(f\"Year bin - size {bin_size} years\")\n",
    "plt.ylabel('Temp Swing (Max-Min)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#box plot of full data in bins\n",
    "red_diamond = dict(markerfacecolor='r', marker='D')\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Temperature Swing in Winter')\n",
    "ax1.set_ylabel('Temp Swing (Ma)')\n",
    "ax1.set_xlabel(f\"Year bin - size {bin_size} years\")\n",
    "\n",
    "ax1.boxplot([Season_data_df[(Season_data_df[\"Bin\"]==i)&(Season_data_df[\"Month\"]==summer)][\"Temp Swing\"] for i in groups], labels=groups,showfliers = True,\n",
    "            flierprops = red_diamond)\n",
    "plt.show()\n",
    "\n",
    "bin_1 = Season_data_df[Season_data_df[\"Bin\"]==groups[0]][\"Temp Swing\"].tolist()\n",
    "bin_2 = Season_data_df[Season_data_df[\"Bin\"]==groups[1]][\"Temp Swing\"].tolist()\n",
    "bin_3 = Season_data_df[Season_data_df[\"Bin\"]==groups[2]][\"Temp Swing\"].tolist()\n",
    "bin_4 = Season_data_df[Season_data_df[\"Bin\"]==groups[3]][\"Temp Swing\"].tolist()\n",
    "f_oneway(bin_1, bin_2, bin_3, bin_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyzing Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing Total Precipitation Each Year \n",
    "print(f\"Regression Analysis for Total Yearly Precipitation versus Year\")\n",
    "\n",
    "precip_comb_df = temp_comb_df.groupby([\"Year\"])[\"Total Monthly Precipitation\",\"Month\"].sum().reset_index()\n",
    "precip_comb_df = precip_comb_df.rename(columns = {\"Total Monthly Precipitation\":\"Total Yearly Precipitation (in)\"})\n",
    "precip_comb_df=precip_comb_df.drop(70) #dropping 2020 since incomplete\n",
    "\n",
    "\n",
    "x_axis = precip_comb_df[\"Year\"]\n",
    "y_axis = precip_comb_df[\"Total Yearly Precipitation (in)\"]\n",
    "\n",
    "max_y = y_axis.max()\n",
    "min_x = x_axis.min()\n",
    "plt.scatter(x_axis,y_axis, s = 4)\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_axis,y_axis)\n",
    "regress_values_N = x_axis * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,3)) + \"x + \" + str(round(intercept_N,3))+\", r = \" +str(round(rvalue_N,3))\\\n",
    "                        + \" p = \"+str(round(pvalue_N,3))\n",
    "plt.plot(x_axis,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.title(\"Total Precipitation by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Precipitation (inches)\")  #need to double check units - temperature is F, would precip be inches\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_axis[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_min = precip_comb_df[\"Year\"].min()\n",
    "year_max = precip_comb_df[\"Year\"].max()\n",
    "delta_year = year_max-year_min\n",
    "delta_year\n",
    "bin_size = 17 #number of years\n",
    "\n",
    "bins = [(year_min+i*bin_size) for i in range(0,int(delta_year/bin_size)+1)]\n",
    "groups = [((i-1)*bin_size+(1951+bin_size/2)) for i in range(1,int(delta_year/bin_size)+1)]\n",
    "precip_comb_df[\"Bin\"]=pd.cut(precip_comb_df[\"Year\"],bins, labels = groups, include_lowest = True)\n",
    "\n",
    "print(f\"Analysis of Hypothesis for Precipitation\")\n",
    "print(\"\")\n",
    "#box plot of full data in bins\n",
    "red_diamond = dict(markerfacecolor='r', marker='D')\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Precipitation over years')\n",
    "ax1.set_ylabel('Precipitation (in)')\n",
    "ax1.set_xlabel(f\"Year bin - size {bin_size} years\")\n",
    "\n",
    "ax1.boxplot([precip_comb_df[(precip_comb_df[\"Bin\"]==i)][\"Total Yearly Precipitation (in)\"] for i in groups], labels=groups,showfliers = True,\n",
    "            flierprops = red_diamond)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "bin_1 = precip_comb_df[precip_comb_df[\"Bin\"]==groups[0]][\"Total Yearly Precipitation (in)\"].tolist()\n",
    "bin_2 = precip_comb_df[precip_comb_df[\"Bin\"]==groups[1]][\"Total Yearly Precipitation (in)\"].tolist()\n",
    "bin_3 = precip_comb_df[precip_comb_df[\"Bin\"]==groups[2]][\"Total Yearly Precipitation (in)\"].tolist()\n",
    "bin_4 = precip_comb_df[precip_comb_df[\"Bin\"]==groups[3]][\"Total Yearly Precipitation (in)\"].tolist()\n",
    "print(\"f_oneway(bin_1, bin_2, bin_3, bin_4)\")\n",
    "\n",
    "print(f\"The p-value is less than 5% so we reject the Null Hypothesis - Precipitation is Changing with Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeff's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faduma's code starts here\n",
    "df = pd.read_csv('Temperature_Data/Temp_Data.csv')\n",
    "\n",
    "#Variables assigned to season\n",
    "count = 0\n",
    "winter = 1\n",
    "spring = 4\n",
    "summer = 7\n",
    "fall = 10\n",
    "\n",
    "#variables for data being found\n",
    "summer_temp_avg = []\n",
    "summer_temp_max = []\n",
    "summer_temp_min = []\n",
    "winter_temp_avg = []\n",
    "winter_temp_max = []\n",
    "winter_temp_min = []\n",
    "spring_temp_avg = []\n",
    "spring_temp_max = []\n",
    "spring_temp_max = []\n",
    "spring_temp_min = []\n",
    "fall_temp_avg = []\n",
    "fall_temp_min = []\n",
    "fall_temp_max = []\n",
    "\n",
    "for i in range(len(df[\"DATE\"])):\n",
    "    try:\n",
    "        date = int(df[\"DATE\"][i].split(\"-\")[1])\n",
    "#print(df[\"TMAX\"][count]) & print(date)\n",
    "        if date < 4:\n",
    "            winter_temp_max.append(float(df[\"TMAX\"][i]))\n",
    "            winter_temp_min.append(float(df[\"TMIN\"][i]))\n",
    "            winter_temp_avg.append(float(df[\"TAVG\"][i]))\n",
    "        elif date < 7:\n",
    "            spring_temp_max.append(float(df[\"TMAX\"][i]))\n",
    "            spring_temp_min.append(float(df[\"TMIN\"][i]))\n",
    "            spring_temp_avg.append(float(df[\"TAVG\"][i]))\n",
    "\n",
    "        elif date < 10:\n",
    "            summer_temp_max.append(float(df[\"TMAX\"][i]))\n",
    "            summer_temp_min.append(float(df[\"TMIN\"][i]))\n",
    "            summer_temp_avg.append(float(df[\"TAVG\"][i]))\n",
    "        else:\n",
    "            fall_temp_max.append(float(df[\"TMAX\"][i]))\n",
    "            fall_temp_min.append(float(df[\"TMIN\"][i]))\n",
    "            fall_temp_avg.append(float(df[\"TAVG\"][i]))\n",
    "        count += 1\n",
    "    \n",
    "    except:\n",
    "        break\n",
    "#printing (maybe into a neater chart?)\n",
    "print(\"Max summer TMAX\", max(summer_temp_max))\n",
    "print(\"Min summer TMIN\", min(summer_temp_min))\n",
    "print(\"Avg summer TAVG\", min(summer_temp_avg))\n",
    "print(\"Max winter TMAX\", max(winter_temp_max))\n",
    "print(\"Min winter TMIN\", min(winter_temp_min))\n",
    "print(\"Avg winter TAVG\", min(winter_temp_avg))\n",
    "\n",
    "print(\"Max spring TMAX\", max(spring_temp_max))\n",
    "print(\"Min spring TMIN\", min(spring_temp_min))\n",
    "print(\"Avg spring TAVG\", min(spring_temp_avg))\n",
    "print(\"Max fall TMAX\", max(fall_temp_max))\n",
    "print(\"Min fall TMIN\", min(fall_temp_min))\n",
    "print(\"AVG fall TAVG\", min(fall_temp_avg))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding Avg Percepation VS year\n",
    "\n",
    "temp_data_df = pd.read_csv('Temperature_Data/Temp_Data.csv')\n",
    "\n",
    "#finding Avg Percepation VS year\n",
    "Avg_pcp = []\n",
    "year_dict = {}\n",
    "for i in range(len(df[\"DATE\"])):\n",
    "    try:\n",
    "        year = (df[\"DATE\"][i]).split(\"-\")[0]\n",
    "        if year not in year_dict:\n",
    "            year_dict[year] = []\n",
    "            year_dict[year].append((df[\"PRCP\"][i]))\n",
    "        else:\n",
    "            year_dict[year].append((df[\"PRCP\"][i]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#more variables:\n",
    "year_lis = []\n",
    "prcp_lis = []\n",
    "\n",
    "for key in year_dict.keys():\n",
    "    if key ==\"DATE\":\n",
    "        continue\n",
    "    year_lis.append(key)\n",
    "    sum_1 = 0.0\n",
    "    #print(year_lis[key])\n",
    "    for i in range(len(year_dict[key])):\n",
    "        #print(year_dict[key][i])\n",
    "        if(np.isnan(float(year_dict[key][i]))):\n",
    "            continue\n",
    "        try:\n",
    "            sum_1 = sum_1 + float(year_dict[key][i])\n",
    "        except:\n",
    "            pass\n",
    "    avg = sum_1/len(year_dict[key])\n",
    "    prcp_lis.append(avg)\n",
    "\n",
    "#print(year_lis)\n",
    "#print(prcp_lis)\n",
    "\n",
    "for i in range(0,len(year_lis)):\n",
    "    year_lis[i] = float(year_lis[i]) \n",
    "\n",
    "year_lis = np.array(year_lis)#convert format so works incalculation for regression\n",
    "min_x = min(year_lis)\n",
    "max_y = max(prcp_lis)\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(year_lis, prcp_lis,linestyle='-', marker='o') \n",
    "  \n",
    "#x axis label\n",
    "plt.xlabel('year') \n",
    "#y axis label\n",
    "plt.ylabel('prcp avg (mm)') \n",
    "#title to my graph \n",
    "plt.title('year vs prcp') \n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(year_lis,prcp_lis)\n",
    "regress_values_N = year_lis * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,3)) + \"x + \" + str(round(intercept_N,3))+\", r = \" +str(round(rvalue_N,3))\\\n",
    "                        + \" p = \"+str(round(pvalue_N,3))\n",
    "plt.plot(year_lis,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "\n",
    "#show the plot! \n",
    "plt.show()\n",
    "\n",
    "# Faduma's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_data = pd.read_csv('Resources/clean_storm_event_data.csv')\n",
    "storm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_data['Event Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of Tornado Eventsin Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = storm_data[\"Year\"].unique()\n",
    "event_list = storm_data[\"Event Type\"].unique()\n",
    "\n",
    "\n",
    "clean_tornado_df = pd.DataFrame()\n",
    "clean_tornado_df = storm_data[storm_data[\"Event Type\"]==\"Tornado\"]\n",
    "\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_tornado_df[clean_tornado_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Tornado Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of Hail Events in Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_hail_df = pd.DataFrame()\n",
    "clean_hail_df = storm_data[storm_data[\"Event Type\"]==\"Hail\"]\n",
    "\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_hail_df[clean_hail_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Hail Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of Thunderstorm Wind Events in Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_thunderstorm_wind_df = pd.DataFrame()\n",
    "clean_thunderstorm_wind_df = storm_data[storm_data[\"Event Type\"]==\"Thunderstorm Wind\"]\n",
    "\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_thunderstorm_wind_df[clean_thunderstorm_wind_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Thunderstorm/Wind Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Count of Tornado, Thunderstorm/Wind, and Hail Events in Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with just tornado, thunderstorm wind, and hail events only\n",
    "main_events = ['Tornado', 'Thunderstorm Wind', 'Hail']\n",
    "storm_main_events = storm_data.loc[storm_data['Event Type'].isin(main_events)]\n",
    "storm_main_events\n",
    "\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = storm_main_events[storm_main_events[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Tornado, Thunderstorm Wind, and Hail Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Tornado, Thunderstorm Wind, and Hail Events per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_main_events_graph = storm_main_events\n",
    "plt.bar(x_data, y_data)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Number of Tornado, Thunderstorm Wind, and Hail Events per Year\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather events from 1950-1995 (when only tornadoes, thunderstorm wind, and hail events were recorded)\n",
    "\n",
    "storm_events_prior_df = storm_data.loc[((storm_data['Year'] >= 1950) & (storm_data['Year'] < 1995))]\n",
    "storm_events_prior_df\n",
    "\n",
    "# keeping only year and event type\n",
    "storm_events_prior_df = storm_events_prior_df[['Year','Event Type']]\n",
    "storm_events_prior_df\n",
    "\n",
    "# count_storms = storm_events_prior_df.groupby('Event Type').count()\n",
    "# count_storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pie chart for weather events prior to 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather events from 1995-2020\n",
    "later_storm_events_df = storm_data.loc[((storm_data['Year'] > 1995))]\n",
    "later_storm_events_df\n",
    "\n",
    "# keeping only year and event type\n",
    "later_storm_events_df = later_storm_events_df[['Year', 'Event Type']]\n",
    "later_storm_events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of Tornado, Thunderstorm Wind, and Hail Events from 1950 to 1995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We chose to separate out 1950 to 1995 because NOAA only tracked these 3 weather events until 1996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather events from 1950-1995 (when only tornadoes, thunderstorm wind, and hail events were recorded)\n",
    "\n",
    "storm_events_prior_df = storm_data.loc[((storm_data['Year'] >= 1950) & (storm_data['Year'] < 1995))]\n",
    "storm_events_prior_df\n",
    "\n",
    "# keeping only year and event type\n",
    "storm_events_prior_df = storm_events_prior_df[['Year','Event Type']]\n",
    "storm_events_prior_df\n",
    "\n",
    "storm_unique_prior = storm_events_prior_df.groupby('Event Type').count()\n",
    "storm_unique_prior = storm_unique_prior.rename(columns={\n",
    "    'Event Type': 'Event Type',\n",
    "    'Year': 'Number of Events'\n",
    "})\n",
    "storm_unique_prior['Number of Events'] = pd.to_numeric(storm_unique_prior['Number of Events'])\n",
    "storm_unique_prior.sort_values(by=['Number of Events'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pie chart for weather events prior to 1995\n",
    "colors = [\"red\", \"blue\", \"green\"]\n",
    "\n",
    "storm_unique_prior\n",
    "storm_unique_prior.sort_values(by=['Number of Events'], ascending=False).plot.pie(y='Number of Events', colors = colors, autopct=\"%1.1f%%\", shadow=True, startangle=140, figsize=(15,6))\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Percentage of Storm Events from 1950 to 1995\")\n",
    "#plt.savefig(\"output_data/PieTornadoHailThunderstorm19501995.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather events from 1995-2020\n",
    "later_storm_events_df = storm_data.loc[((storm_data['Year'] > 1995))]\n",
    "later_storm_events_df\n",
    "\n",
    "# keeping only year and event type\n",
    "later_storm_events_df = later_storm_events_df[['Year', 'Event Type']]\n",
    "later_storm_events_df\n",
    "\n",
    "storm_unique_later = later_storm_events_df.groupby('Event Type').count()\n",
    "storm_unique_later = storm_unique_later.rename(columns={\n",
    "    'Event Type': 'Event Type',\n",
    "    'Year': 'Number of Events'\n",
    "})\n",
    "storm_unique_later['Number of Events'] = pd.to_numeric(storm_unique_later['Number of Events'])\n",
    "storm_unique_later.sort_values(by=['Number of Events'], ascending=False)\n",
    "\n",
    "\n",
    "# create pie chart for weather events after 1995\n",
    "explode = [.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "storm_unique_later.sort_values(by=['Number of Events'], ascending=False).plot.pie(y='Number of Events',labeldistance=None,\\\n",
    "                            autopct=\"%1.1f%%\",textprops={'fontsize': 30}, explode=explode,\\\n",
    "                            pctdistance=1.1,shadow=True, figsize=(50,40))\n",
    "plt.legend(loc=2, prop={'size': 20})\n",
    "\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Percentage of Storm Events from 1996 to 2020\", fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily's code ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
