{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import random as random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import linregress\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeff Code\n",
    "\n",
    "#Functions to be used for code\n",
    "\n",
    "#Function #1\n",
    "#plotting routine with regression (setting up as a function)\n",
    "#below function takes 2 sets of x and y data and generates a scatter plot for each.  Then performs a linear regression \n",
    "#and returns a dataframe with the regression results\n",
    "#x and y are number pairs\n",
    "#data is the name of what is being plotted (like temperature).  used as Y axis label and as part of title\n",
    "#prints results of regression below graphs\n",
    "\n",
    "def plotter(x1,y1,Data1,x2,y2,Data2):\n",
    "   \n",
    "   #plotting data set x1 and y1\n",
    "\n",
    "    (slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x1,y1)\n",
    "    regress_values_N = x1 * slope_N + intercept_N\n",
    "    line_eq = \"y = \" + str(round(slope_N,3)) + \"x + \" + str(round(intercept_N,3))+\", r = \" +str(round(rvalue_N,3))\\\n",
    "                        + \" p = \"+str(round(pvalue_N,3))\n",
    "    max_y = y1.max()\n",
    "    min_x = x1.min()\n",
    "    fig = plt.figure(figsize = (15,4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.scatter(x1, y1, s=5)\n",
    "    plt.plot(x1,regress_values_N,\"r-\")\n",
    "    plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(f\"{Data1} \")\n",
    "    plt.title(f\"{Data1} vs Year\")\n",
    "\n",
    "  #plotting data set x2 and y2\n",
    "    (slope_S, intercept_S, rvalue_S, pvalue_S, stderr_S) = linregress(x2,y2)\n",
    "    regress_values_S = x2 * slope_S + intercept_S\n",
    "    line_eq = \"y = \" + str(round(slope_S,3)) + \"x + \" + str(round(intercept_S,3))+\", r = \" +str(round(rvalue_S,3))\\\n",
    "                        + \" p = \"+str(round(pvalue_S,3))\n",
    "    max_y = y2.max()\n",
    "    min_x = x2.min()\n",
    "    #plotting second data set\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(x2, y2, s=5)\n",
    "    plt.plot(x2,regress_values_S,\"r-\")\n",
    "    plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(f\"{Data2}\")\n",
    "    plt.title(f\"{Data2} vs Year\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    Result_Temp_df = pd.DataFrame({\"Slope\":[slope_N, slope_S], \"Intercept\":[intercept_N, intercept_S], \n",
    "                                                         \"r-value\":[rvalue_N, rvalue_S], \"p-value\":[pvalue_N, pvalue_S]})\n",
    "\n",
    "    Result_Temp_df[\"Param\"] =[Data1, Data2]\n",
    "    Result_Temp_df = Result_Temp_df[[\"Param\", \"Slope\", \"Intercept\", \"r-value\", \"p-value\"]]\n",
    "\n",
    "    print(f\"Correlation Results\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(Result_Temp_df)\n",
    "    return Result_Temp_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kristina's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kristina's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeff's code starts here\n",
    "\n",
    "#reading in raw data\n",
    "temp_data_df = pd.read_csv('Resources/clean_temp_data.csv')\n",
    "temp_data_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = temp_data_df.columns\n",
    "print(\"Before\")\n",
    "for i in names:\n",
    "    full = temp_data_df[i].count()\n",
    "    Null = temp_data_df[i].isnull().sum(axis = 0)\n",
    "    print(f\"for {i} column: Full {full} vs Empty or NaN {Null}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeff's code ends here\n",
    "\n",
    "\n",
    "#removing NaN\n",
    "Start_Length = len(temp_data_df[\"Date\"])\n",
    "temp_data_df.dropna(inplace = True)\n",
    "\n",
    "#temp_data_df\n",
    "Finish_Length = len(temp_data_df[\"Date\"])\n",
    "print(f\"Temperature and precipitation data starts with {Start_Length} records\")\n",
    "print(f\"After removing rows with empty data fields have {Finish_Length} records\")\n",
    "\n",
    "#code below combines all locations into one average value for month and year\n",
    "list = temp_data_df[\"Name\"].unique()\n",
    "temp_comb_df = temp_data_df.groupby([\"Date\"])[\"Total Monthly Precipitation\", \"Total Montly Snowfall (mm)\",\n",
    "                                             \"Avg Monthly Temp\", \"Monthly Mean Max Temp\",\n",
    "                                              \"Monthly Mean Min Temp\"].mean().reset_index()\n",
    "\n",
    "#Data is string Year-Month (month two digits 01-12).  This splits into two fields\n",
    "temp_comb_df[\"Month\"] = temp_comb_df[\"Date\"].str.split(\"-\").str[1].astype(int)\n",
    "temp_comb_df[\"Year\"] = temp_comb_df[\"Date\"].str.split(\"-\").str[0].astype(int)\n",
    "\n",
    "col_list = temp_comb_df.columns.tolist()\n",
    "Season_data_df = pd.DataFrame(columns = col_list)\n",
    "\n",
    "#combining months to form seasons: Winter (Dec-Feb), Fall(Mar-May), Summer(June-Aug), Fall(Sept-Nov)\n",
    "for i in temp_comb_df[\"Year\"].unique():\n",
    "    if i!= 1950 and i!= 2020: #ignore 1950 because don't have dec 1949 and don't have all 2020\n",
    "        \n",
    "        #in dataframe the \"month\" represents the season: 2=winter, 4 = spring, 7 = summer, 10=fall\n",
    "        winter_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(1,2)))|\\\n",
    "                                         ((temp_comb_df[\"Year\"]==(i-1)) & (temp_comb_df[\"Month\"]==12))].mean()\n",
    "        winter_data[\"Year\"]=winter_data[\"Year\"].astype(int)+1 # extra 1 because rounds down to year previous\n",
    "        winter_data[\"Month\"] = 1 #would be 5 otherwise (mean(12,1,2))\n",
    "        spring_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(3,5)))].mean()\n",
    "        spring_data[\"Year\"]=spring_data[\"Year\"].astype(int)\n",
    "        summer_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(6,8)))].mean()\n",
    "        summer_data[\"Year\"]=summer_data[\"Year\"].astype(int)\n",
    "        fall_data = temp_comb_df.loc[((temp_comb_df[\"Year\"]==i) & (temp_comb_df[\"Month\"].between(9,11)))].mean() \n",
    "        fall_data[\"Year\"]=fall_data[\"Year\"].astype(int)\n",
    "        \n",
    "        frames = [winter_data, spring_data, summer_data, fall_data]\n",
    "        Season_data_df = Season_data_df.append(frames, ignore_index = True)\n",
    "        \n",
    "winter = 1\n",
    "sprint = 4\n",
    "summer = 7\n",
    "fall = 10\n",
    "Season_data_df[\"Temp Swing\"] = Season_data_df[\"Monthly Mean Max Temp\"]-Season_data_df[\"Monthly Mean Min Temp\"]\n",
    "Season_data_df.drop(columns=[\"Date\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"Temp Swing\" #pick variable to look at\n",
    "\n",
    "#defining seasons by value in month column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = \"Monthly Mean Min Temp\"\n",
    "x1 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y1 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data1]\n",
    "Data2 = \"Monthly Mean Max Temp\"\n",
    "x2 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y2 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data2]\n",
    "print(\"\")\n",
    "print(f\"Minimum and Maximum Avg Temperatures for Winter Months\")\n",
    "print(\"\")\n",
    "Data1 = Data1 + \" (Winter)\"\n",
    "Data2= Data2 + \" (Winter)\"\n",
    "Correlation_df = plotter(x1,y1,Data1,x2,y2,Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = \"Temp Swing\"\n",
    "x1 =  Season_data_df[Season_data_df[\"Month\"]==winter][\"Year\"]\n",
    "y1 =  Season_data_df[Season_data_df[\"Month\"]==winter][Data1]\n",
    "Data2 = \"Temp Swing\"\n",
    "x2 =  Season_data_df[Season_data_df[\"Month\"]==summer][\"Year\"]\n",
    "y2 =  Season_data_df[Season_data_df[\"Month\"]==summer][Data2]\n",
    "print(\"\")\n",
    "print(f\"Avg Temperature Swings for Winter and Summer (Seasonal max - seasonal min)\")\n",
    "print(\"\")\n",
    "Data1 = Data1 +\" Winter\"\n",
    "Data2 = Data2 +\" Summer\"\n",
    "Correlation_df = plotter(x1,y1,Data1,x2,y2,Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for Winter\n",
    "#chi2 test\n",
    "#binning data for analysis\n",
    "year_min = Season_data_df[\"Year\"].min()\n",
    "year_max = Season_data_df[\"Year\"].max()\n",
    "delta_year = year_max-year_min\n",
    "delta_year\n",
    "bin_size = 4 #number of years\n",
    "\n",
    "bins = [(year_min+i*bin_size) for i in range(0,int(delta_year/bin_size)+1)]\n",
    "groups = [((i-1)*4+1953) for i in range(1,int(delta_year/bin_size)+1)]\n",
    "Season_data_df[\"Bin\"]=pd.cut(Season_data_df[\"Year\"],bins, labels = groups, include_lowest = True)\n",
    "\n",
    "#Calculating Winter Binning Summary\n",
    "Season_group_df = Season_data_df[Season_data_df[\"Month\"] == 1].groupby(\"Bin\")[\"Total Monthly Precipitation\", \"Total Montly Snowfall (mm)\",\n",
    "                                             \"Avg Monthly Temp\", \"Monthly Mean Max Temp\",\n",
    "                                              \"Monthly Mean Min Temp\", \"Temp Swing\"].mean().reset_index()\n",
    "\n",
    "Param = \"Temp Swing\"\n",
    "y_axis = Season_group_df[Param].tolist()\n",
    "Param_mean = Season_group_df[Param].mean()\n",
    "Control_list = [Param_mean for i in range(0,len(y_axis))]\n",
    "# print(Param_mean)\n",
    "# print(y_axis)\n",
    "# print(Control_list)\n",
    "\n",
    "plt.bar(groups, y_axis, color='r', alpha=0.9, align=\"center\")\n",
    "plt.ylim(min(y_axis)-1, max(y_axis)+1)\n",
    "plt.ylabel(\"Temp Swing (Winter) \\n 4 year average bin size\")\n",
    "plt.xlabel(\"Year (Bin)\")\n",
    "plt.title(\"Bar graph of Temp Swing (winter) versus binned year \\n (4 years average together)\")\n",
    "\n",
    "stats.chisquare(y_axis, Control_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeff's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faduma's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faduma's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_data = pd.read_csv('Resources/clean_storm_event_data.csv')\n",
    "storm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_data['Event Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of Tornado Eventsin Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = storm_data[\"Year\"].unique()\n",
    "event_list = storm_data[\"Event Type\"].unique()\n",
    "\n",
    "\n",
    "clean_tornado_df = pd.DataFrame()\n",
    "clean_tornado_df = storm_data[storm_data[\"Event Type\"]==\"Tornado\"]\n",
    "\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_tornado_df[clean_tornado_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Tornado Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of Hail Events in Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_hail_df = pd.DataFrame()\n",
    "clean_hail_df = storm_data[storm_data[\"Event Type\"]==\"Hail\"]\n",
    "\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_hail_df[clean_hail_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Hail Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of Thunderstorm Wind Events in Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_thunderstorm_wind_df = pd.DataFrame()\n",
    "clean_thunderstorm_wind_df = storm_data[storm_data[\"Event Type\"]==\"Thunderstorm Wind\"]\n",
    "\n",
    "\n",
    "#clean_storm_data_mn_df\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = clean_thunderstorm_wind_df[clean_thunderstorm_wind_df[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Thunderstorm/Wind Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Count of Tornado, Thunderstorm/Wind, and Hail Events in Minnesota from 1950 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with just tornado, thunderstorm wind, and hail events only\n",
    "main_events = ['Tornado', 'Thunderstorm Wind', 'Hail']\n",
    "storm_main_events = storm_data.loc[storm_data['Event Type'].isin(main_events)]\n",
    "storm_main_events\n",
    "\n",
    "year_count_df = pd.DataFrame()\n",
    "for i in year_list:\n",
    "    year_count = storm_main_events[storm_main_events[\"Year\"]==i][\"Event Type\"].count()\n",
    "    year_count_df = year_count_df.append({\"Year\":i, \"Count\":year_count}, ignore_index=True)\n",
    "year_count_df\n",
    "\n",
    "x_data = (year_count_df[\"Year\"].astype(int))\n",
    "y_data = year_count_df[\"Count\"].astype(float)\n",
    "\n",
    "plt.scatter(x_data,y_data, s = 4)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Counts of Tornado, Thunderstorm Wind, and Hail Events vs Year\")\n",
    "\n",
    "(slope_N, intercept_N, rvalue_N, pvalue_N, stderr_N) = linregress(x_data,y_data)\n",
    "regress_values_N = x_data * slope_N + intercept_N\n",
    "line_eq = \"y = \" + str(round(slope_N,2)) + \"x + \" + str(round(intercept_N,2))+\", r = \" +str(round(rvalue_N,2))+\", p=\"+str(round(pvalue_N,2))\n",
    "min_x = x_data.min()\n",
    "max_y = y_data.max()\n",
    "plt.plot(x_data,regress_values_N,\"r-\")\n",
    "plt.annotate(line_eq,(min_x+1,max_y-1),fontsize=11,color=\"red\") #writes to coordinates on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Tornado, Thunderstorm Wind, and Hail Events per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_main_events_graph = storm_main_events\n",
    "plt.bar(x_data, y_data)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Number of Tornado, Thunderstorm Wind, and Hail Events per Year\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather events from 1950-1995 (when only tornadoes, thunderstorm wind, and hail events were recorded)\n",
    "\n",
    "storm_events_prior_df = storm_data.loc[((storm_data['Year'] >= 1950) & (storm_data['Year'] < 1995))]\n",
    "storm_events_prior_df\n",
    "\n",
    "# keeping only year and event type\n",
    "storm_events_prior_df = storm_events_prior_df[['Year','Event Type']]\n",
    "storm_events_prior_df\n",
    "\n",
    "# count_storms = storm_events_prior_df.groupby('Event Type').count()\n",
    "# count_storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pie chart for weather events prior to 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather events from 1995-2020\n",
    "later_storm_events_df = storm_data.loc[((storm_data['Year'] > 1995))]\n",
    "later_storm_events_df\n",
    "\n",
    "# keeping only year and event type\n",
    "later_storm_events_df = later_storm_events_df[['Year', 'Event Type']]\n",
    "later_storm_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily's code ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
